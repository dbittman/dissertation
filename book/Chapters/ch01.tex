
\chapter{Introduction}\label{ch:intro}

\emph{Let's design and build a new operating system.}

\section*{The Problem}

The confluence of several hardware trends---persistent memory moving up the memory hierarchy, faster interconnect
technologies, and increasing heterogeneity of compute and memory---demands a fundamental shift in how we view
applications' relationships with hardware and data. As persistence gets closer to compute, the line separating the traditional two-tier
memory hierarchy of fast, volatile memory and slow, persistent storage begins to blur. As interconnect technologies
improve, separate computing nodes are drawn closer to each other in latency space, allowing them to more efficiently
share memory. As computing resources spread out, as we race to place computing units in devices and near memory, and as
we start seeing different kinds of physical memory on the bus, the traditional host-centric and process-centric models
of programming give way to models that better express the increasing demands for concurrency and parallelism between
devices and computers.

Software both drives some of these trends, as it demands increasing throughput and lower latency when processing data,
but is also affected by the trends, or more specifically, often limited in expressivity to what \emph{abstractions} are
presented to software by the operating system\sidenote{OS abstractions, the common punching bag among systems.}. The primary goal of a program is to access and operate on data and any
additional required work that an application must perform enable that goal is overhead, both in terms of performance
(latency or throughput) but also \emph{complexity}. Applications must routinely engage in, for example, serialization
when persisting data, marshalling that data across a network, or when sharing data between processes, which not only
costs CPU time but also programmer time to define and maintain additional data formats. This overhead sources from the
abstractions and programming model enabled by the operating system, which is sourced from a model of hardware decades
old. Traditional operating system abstractions and interfaces do not adequately reflect current hardware, the direction hardware is
heading, nor the demands of software upon those interfaces.

\section*{The Opportunity}

\squo{Two roads diverged in a wood, and I---\\ I took the one less traveled by, \\ And that has made all the difference.}{Robert Frost}

We have an opportunity to examine hardware trends and evolve operating system design to make the best possible use of
new technologies and trends. Mere incremental change will not enable the dramatic improvements in performance and
complexity heralded by these trends, just as SSDs did not reach their full potential
until they transcended the disk paradigm\sidenote{Arguably, they still haven't. SSDs were, for a long time, treated as
    ``fast disks'', to the detriment of our storage stacks.}. Instead, we will discuss and examine a ``clean-slate'' approach to
operating system design that avoids trying to mold new hardware into some backwards-compatible existing
box\sidenote{Imagine if we tried to access, say, persistent RAM with interfaces designed for magnetic tape! \emph{Stares
        straight into the camera.}}. Such an
approach will necessitate examining past research and reconsidering previously impractical ideas\sidenote{Knowledge
    derives from experience of the world, but what if that world were to change?} while extending those
ideas for modern software, hardware, and languages. Simultaneously, we must design new abstractions and interfaces that
expose a programming model that allows applications to center around the data they are accessing while not requiring
them to twist into knots trying to best utilize modern hardware.

Our focus will be on a \emph{data-centric} approach, in which \emph{data} is the primary citizen instead of the process.
As we will see, this framing around data forces us to reconsider and reimagine classic systems programming tropes like serialization,
explicit, course-grained persistence barriers, call-by-small-value RPC, shared memory, and in-memory data structures
that cannot escape the bounds of a single process\sidenote{See Chapter~\ref{ch:softwaredemands}.}. We will define a design space for data-centric operating systems that
centers around in-memory data in a global address spaces that can be shared across both space and time, whose lifetime
is disconnected from ephemera like processes, nodes, and virtual address spaces, and which can be operated on,
persisted, and shared without the overhead of serialization of operating system involvement in the data access
path\sidenote{See Chapter~\ref{ch:datacentric}.}.
In a world where in-memory data can last forever and move across processes and nodes, the context required to manipulate
that data is best coupled with the \emph{data} rather than ephemeral constructs.
Data has always been the focus of programming; it's time our operating system abstractions adequately capture this
simple fact.


\section*{The Implementation}

The principal hypothesis of this dissertation is that the data-centric model for designing operating system abstractions
is not only viable, but demanded both by software and hardware trends. Examining this hypothesis will require answering
a number of questions about the design space, the practicality of any implementation of our ideas, and empirical
measurements of that implementation. To study data-centric operating system design, we have built \emph{Twizzler}, an
operating system that embodies the ideas presented herein.

Twizzler consists of a standalone kernel built from scratch, a set of userspace libraries for programming memory, and a
set of applications we wrote and ported for evaluation. It provides a rich environment for programming in-memory data
structures that can be shared and persisted by presenting data access as memory access within a (very) large global
address space in which references to \emph{any other piece of data} are efficiently encoded. Traditional operating
system abstractions reflect the hardware they are designed for, and Twizzler is no different. Twizzler's abstractions
for data access center around two core concepts: \textbf{remove the kernel from the data path}, and \textbf{enable the
    construction of in-memory data that is free from ephemeral context}. We will see how these core concepts manifest, both
in how they enable new ways of building applications and in how they improve performance when accessing data.

\section*{The Claims}

This dissertation, in addition to investigating the aforementioned principal hypothesis, makes the following claims:

\begin{enumerate}
    \item Retrofitting existing interfaces is insufficient. Instead, the correct approach to reimagining programming in
          a world of changing memories is to rebuild the operating system from the ground up.
          Similarly, Backwards compatibility, while important, is not the primary goal of a reimagined operating system.
          Applications that want to adapt to new hardware trends should get first-class support.
    \item A global address space of all data is a viable design for long-lived, in-memory data structures, and access to
          that address space can be done efficiently with little kernel involvement\sidenote{See Chapter~\ref{ch:global}.}.
    \item The implementation of references within the global address space matters beyond simple performance tradeoffs.
          We can
          encode references within the address space to not only be \emph{invariant}---\ie not based on any local
          context---but we can also encode them efficiently, despite the address space being large, with less space
          overhead than alternative approaches\sidenote{See Chapter~\ref{ch:invariant}.}.
\end{enumerate}

We will examine these claims in more detail throughout the following chapters, keeping in mind the goal---that by
providing in-memory data structures that don't require kernel intervention in the data access path we can center
programming around data instead of actors. Showing a viable approach to low-coordination global data naming and
accessing is the primary piece of the puzzle. But after we place this puzzle piece, there is still much work to do---the
operating system must provide basic services, convenience libraries, interfaces for ensuring safety in
failure-atomicity and type correctness for persistent data, and (last but \emph{certainly} not least)
security\sidenote{See Chapters~\ref{ch:twizzler} and~\ref{ch:prog}.}. These
aspects are no less important than the enumerated claims, however we will approach them in such a way that ties
them back to be fundamentally derived from the core concepts of Twizzler and the claims above.

\section*{The Signposting}

\squo{“Being lost is not a matter of knowing where you are. It's a matter of knowing where you aren't.”}{
    \emph{The Phantom Tollbooth}, Norton Juster}

\noindent\textbf{Chapter~\ref{ch:farout}} discusses, in detail, the hardware trends we are considering and the implications they
hold, followed by a discussion of how those trends will inform our operating system design work.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:softwaredemands}} covers the software demands of hardware and interfaces, primarily focused on
the overheads that software has to deal with to get around ``the context problem''. We will cover
serialization\sidenote{\emph{``Boo''ing sounds}.} for
persistence and distribution as well as patterns of RPC.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:datacentric}} combines the insights from the previous two chapters and discusses data-centric
operating system design, introduces Twizzler, and provides an overview of relevant operating system, persistent memory,
and systems research.

\vspace{2em}

\noindent Following Chapter~\ref{ch:datacentric}, we begin to focus more specifically on the design and implementation choices we
made for Twizzler, studying them in case studies, performance analysis, and modeling.
\textbf{Chapter~\ref{ch:global}} covers the design of the global address space in Twizzler, the model of data objects
Twizzler uses, and models the collision possibility of object IDs within the space. Finally, it discusses how the global
address space is realized and accessed on existing hardware.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:invariant}} discusses how we encode references within the global address space, introduces the
\emph{foreign object table}, our solution to naming data in an invariant fashion, and performs case-studies on using
invariant references to build real data structures that serve as a backend to a ported version of SQLite. These software
are then evaluated for performance and compared to other solutions to persistent memory programming.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:twizzler}} enumerates several core aspects of Twizzler as an operating system, such as object
services, program instancing, threading, security, and \unix compatibility.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:prog}} goes over higher level programming concepts, such as failure-atomicity, type safety,
memory safety, crash consistency, and new programming patterns enabled by Twizzler's object and invariant references
model.

\vspace{2em}

\noindent\textbf{Chapter~\ref{ch:conclusion}} concludes with a look back on the work presented here and a look to the future for
operating systems and for Twizzler, and data-centric designs.


\chendsep

Twizzler is open-source and can be found at \url{twizzler.io}\sidenote{You can tell that it's a noteworthy project
    because the \href{https://mail.gnu.org/archive/html/config-patches/2019-09/msg00001.html}{GNU config.sub file recognizes
        it}.}.
