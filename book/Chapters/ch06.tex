
\chapter{Invariant References}\label{ch:invariant}

\begin{chabstract}
    This chapter builds up the notion of data references within the global address space discussed in the previous chapter by way of introducing the key abstraction that underpins
    Twizzler---the invariant reference. We will discuss the design and implementation of invariant references along with several case studies and performance analyses.
\end{chabstract}


Last chapter, we discussed how we can name any piece of data within the global address space using a tuple of object ID
and offset. However, with a large object ID space and an offset value, the tuple is quite big (192~bits). If we want to
encode a reference to a piece of data, any pointers needs to encode all that information. But our current virtual
address pointers are 64~bits wide, so we would be increasing our overhead over virtual addresses by a factor of 3.
Instead, Twizzler uses an \emph{invariant pointer} abstraction that reduces overhead and maintains pointer sizes at
64~bits while making it possible to refer to any data in the global address space (thus, these pointers are inherently
cross-object or inter-object), and exposing object relationships to lower level parts of the system stack that would
traditionally be blind to such relationships.

\section{Implementation}

%% TODO distinguish between persistent pointers and invariant pointers.

The authoritative name for a piece of data as defined in the previous chapter is,
\begin{equation*}
    (
    \eqnmarkbox[NavyBlue]{g}{I_O}
    , \eqnmarkbox[Orange]{o}{N})
\end{equation*}
\annotate[yshift=0.5em]{above}{g}{ID of object $O$}
\annotate[yshift=-0.2em]{below}{o}{An offset into an object}

To efficiently encode this tuple, we use indirection through a per-object \textit{foreign
    object table} (FOT), located at a known offset within each object. The FOT is an array of entries
that each stores an object ID (or a name that resolves into an object ID, as we will see
below) and flags. An invariant pointer is thus a tuple,
\begin{equation*}
    (
    \eqnmarkbox[NavyBlue]{f}{f}
    , \eqnmarkbox[Orange]{n}{N})
\end{equation*}
\annotate[yshift=0.5em]{above}{f}{Index into the FOT}
\annotate[yshift=-0.2em]{below}{n}{An offset into an object}

This tuple is encoded into 64~bits by placing the $f$ into the upper 24~bits and placing $N$ into the lower bits. When
We can then recover the original tuple by performing an FOT lookup. For example, if we have an invariant pointer in
object $O$, the lookup is:

\begin{equation*}
    (
    \eqnmarkbox[Red]{f}{I_T}
    , \eqnmarkbox[Orange]{n}{N}) = (
    \mathrm{\eqnmarkbox[Green]{fot}{FOT}}(\eqnmarkbox[NavyBlue]{obj}{O}, \eqnmarkbox[NavyBlue]{f}{f})
    , \eqnmarkbox[Orange]{n}{N}
    )
\end{equation*}
\annotate[yshift=0.5em]{above}{f}{Index into the FOT}
\annotate[yshift=-0.2em]{below}{n}{An offset into an object}


This provides us
with both large offsets \emph{and} large object IDs, since the IDs are not stored within the pointer
itself.
If an object wishes to point to data within itself (an \emph{intra-object} pointer), it stores $0$ in
\texttt{FOT\_idx}. When dereferencing, \Twizzler uses the \texttt{FOT\_idx} part of the
pointer as an index into the FOT, retrieving an object ID\@.
The combination of a FOT and a cross-object pointer logically forms
an \texttt{object-id:offset} pair, as shown in Figure~\ref{fig:fottran}.

Our design (discussed in prior work~\cite{bittman:hotstorage19,bittman:plos19}) differs from existing
frameworks~\cite{corbato_introduction_1965,bensoussan:sosp69,daley:cacm68,pmdk-pointers,libpmem,Chen:micro17}
because of the indirection. Frameworks like PMDK store entire object IDs within pointers,
increasing pointer size and reducing flexibility by removing
the possibility of late-binding (discussed below). Additionally, \Twizzler extends the
namespace of data objects beyond one machine, as machine-independent data references
are a natural consequence of cross-object pointers. Existing solutions are limited
in this scalability. They either limit the ID space (necessary for storing IDs
in pointers) and thus resort to complex coordination or serialization when sharing, or
they require additional state (\eg per-process or per-machine ID tables) that must
be shared along with the data, forcing the receiving machine to ``fix-up''
references. Worse still, the fix-up is application-specific, since the object IDs are
within any pointer, not in a generically known location.
Our per-object FOT results in self-contained objects that are easier to share, thus interacting better with remote shared memory systems.

Part of our motivation for indirecting pointers through the FOT was to allow a large ID space
without increasing pointer size. The density of \NVM and the disaggregation of memory and
applications means that we will be accessing data in a larger and larger address space, and it is
vital that our abstractions allow for a large enough ID space to cover these needs. Since our IDs
are 128~bits and our offsets need to support large objects, replacing pointers with a ``fat
pointer'' style of just \texttt{object-id}:\texttt{offset} would mean more than doubling pointer
size, which we found unacceptable. Other frameworks like PMDK, by contrast, increase pointer size to 128~bits for each
pointer by encoding pointers as this tuple with 64~bit object IDs. The trade off is that our
pointers take a little more work to translate (as they require an FOT lookup), but in return we keep
pointers 64~bits while supporting a truly global-scale address space. Thus the overall space trade off is, for \Twizzler, no additional space overhead
per pointer, but an added 32-byte overhead per FOT entry.
The number of FOT entries, however, is typically much smaller than the number of
pointers since pointers to the same external object can all use the same FOT entry. As we will see
in Section~\ref{sec:res}, this has a dramatic benefit to performance.


\paragraph{FOT Entries and Late-Binding.}

The FOT entry's \texttt{flags} field has bits for read, write, and execute protections. The
protections are \textit{requests}; \Twizzler implements separate access control on objects.
This allows some pointers to refer to data with a read-only reference while others can be used for
writing, reducing stray writes (a single ID can repeat in the FOT with different protections).
The FOT entries also enable atomic updates that apply to all pointers using
that FOT entry.
%Additionally, the flags can contain other information, such as
%reference counts, which can be updated atomically for all pointers using that FOT entry.

\begin{SCfigure}[tb]
    \includegraphics[width=\linewidth]{fig/ptrfot}
    \caption{Pointer translation via the FOT\@.
        The pointer and the FOT
        are both contained in the same object (not shown). An FOT entry of $0$ indicates an ``internal''
        pointer.
    }
    \label{fig:fottran}
\end{SCfigure}

Instead of \emph{requiring} programmers to refer to objects via IDs only, we allow
names in FOT entries. These entries may contain a pointer to an
in-object string table that contains a name.
%and a function pointer that resolves the name into an
%object ID.
Names enable late-binding~\cite{daley:cacm68}, a
vital aspect of systems, allowing references to objects which change over time, \eg shared library versions.
Names are passed to a \textit{resolving} function (specified in the FOT entry).
Allowing a program to specify how its names are resolved
increases the flexibility of the system beyond supporting \unix paths. \Twizzler
provides a default name resolver that uses \unix-like paths.% for ease of development of simpler applications.

The implementation of naming is orthogonal to \Twizzler's design. We
allow a range of name resolution methods within the system stack
and allow objects to specify their own name resolution functions for flexibility. For example,
objects could be organized by both a relational database and a hierarchical namer
similar to conventional file systems. Non-hierarchical file systems
are well studied~\cite{gifford:sosp91, ames:mss06, padioleau:usenix03, gopal:osdi99,
    parkerwood:systor14}, but these systems do not easily cooperate atop a single data space.
Since \Twizzler uses a flat namespace as its ``native'' object naming scheme, it
enables the required cooperation.


\unedit {
    \paragraph{Pointer Translation API}

    \Twizzler applications use pointer translation helper functions to handle the
    translations discussed above. These functions, which can be written manually,
    can also be emitted automatically by proper compiler support.
    %In our current implementation, applications
    %must call them explicitly, though the compiler could be modified to emit
    %implicit calls when necessary.
    When a pointer must be
    translated, the program calls \texttt{ptr\_lea} to convert the pointer into a
    virtual address, and \texttt{ptr\_store} to convert a virtual address into a
    cross-object pointer. The results can be cached to reduce translation calls.
    These functions efficiently detect if a pointer needs no translation,
    allowing the compiler to emit calls to these functions for pointers whose
    origin it does not know.

    Given an object ($o$), and a structure in
    the object (\texttt{hdr}) containing a pointer to data, we cannot
    dereference the pointer directly since it is in cross-object form. We use
    \texttt{ptr\_lea} to convert it into a current virtual address: \\
    \indent\hspace{5mm}\texttt{void *ptr = ptr\_lea(o, hdr->ptr);}\\
    this call returns a virtual address that points to the requested
    data whether \texttt{hdr->ptr} is an internal or cross-object pointer.
    A similar operation on \unix would require calls to \texttt{open}, manually
    written code to store a path to the target object (whether or not it is
    different from $o$), and additional calls to \texttt{read} or \texttt{mmap} to
    get the data---effectively reimplementing \Twizzler's pointer
    framework with more complexity.

    Writing a cross-object pointer is simple as well:
    \\\indent\hspace{5mm}\texttt{hdr->ptr = ptr\_store(o, ptr);}\\
    If \texttt{ptr} is a cross-object pointer, an FOT entry will be added to $o$ if
    needed, and the returned address of \texttt{ptr\_store} will be a cross-object
    pointer to the object pointed to by \texttt{ptr} for storage in $o$. Doing a
    similar operation on \unix would require manual pointer serialization.
    Optimizations like those discussed above can
    turn these into no-ops in many cases. The resulting simplicity of programs and
    enhanced object sharing is
    discussed later, along with an analysis of performance.

    Although some existing persistent memory programming
    techniques~\cite{libpmem,Chen:micro17,wang:micro17} support similar
    APIs, they do not support per-object indirection, they lack system-wide support,
    some increase pointer size and do not always provide
    type-safe translation functions, and they do not enable transparent use of pointer
    types in the language. Implementing translations manually involves writing code
    like
    \texttt{(void *)((uintptr\_t)foo + vbase)}, resulting in brittle code that
    cannot be easily expanded to include cross-object references.

}

\section{Evaluation}

In evaluating Twizzler's invariant pointer design, we investigated both the
usability of the invariant pointer model and the more measurable elements such as performance impact
% TODO cite sqlite
and storage overhead. We approached the evaluation in two ways---porting existing software
(SQLite) and writing new software for Twizzler. The latter demonstrates the true power of
Twizzler's invariant pointer model and allows us to explore better the consequences of our design
choices without being constrained by legacy designs. Porting existing software, however, has the
advantage of demonstrating the flexibility and generality of the model and environment.

We built two pieces of new software for Twizzler: a hash-table based key-value store (KVS) and a red-black tree
data structure.  Each has different characteristics and goals, and together they demonstrate the flexibility that
\Twizzler offers in allowing simple implementation, nearly-free access control, and the ability to directly express
complex relationships between objects.  We then ported SQLite to Twizzler using
our KVS and red-black tree code and evaluated it using a YCSB~\cite{ycsb,ycsbc} driver, thus exploring Twizzler's
model in a larger, existing program. The new software, along with our SQLite port and
microbenchmarks, are evaluated for performance in Section~\ref{sec:perf}, but let's first consider their development and our experiences with writing software in our model.


\subsection{Case Study: Key-Value Store}

%We implemented several applications and data structures to determine the effect of cross-object
%pointers and \Twizzler's design on programming and system functionality.

%\subsubsection*{Key-Value Store}
\label{sec:kv}

We implemented a multi-threaded hash-table based \ac{kvs}, called \nvkv, to
study cross-object pointers and our late-binding of access control.
Our KVS supports insert, lookup, and delete of values by key (both of arbitrary size), and hands
out direct pointers to persistent data during lookup. During insert, it copies data into a data
region before indexing the inserted key and value. We built \nvkv in multiple phases to study how
our system handles changing requirements.

We built \nvkv in roughly 250 lines of C\@. Handing
out direct pointers into data was trivial to implement with cross-object pointers, requiring
only a call to \texttt{ptr\_lea} during lookup. The initial implementation maintains two
objects, one for data and one for the index.  The complexity typically involved when storing both
index and data in a single, flat file is not justified in a programming
model where we can express inter-object relationships directly at
near-zero cost in complexity or performance. In our case, a pointer from the index object
to the data object (such as an entry in the hash table) can be written with a single call to
\texttt{ptr\_store}.
%to translate the pointer from an offset into the data object into a cross-object
%pointer for storage in the index. 
This, combined with the simple requirements for an in-memory \NVM KVS,
resulted in a small implementation that was nonetheless a
usable KVS.

\begin{SCfigure}
    \centering
    \includegraphics[width=\linewidth]{fig/twzkv}
    \caption{Cross-object pointers in \nvkv. The index object contains pointers to keys and values,
        which can reside in any data object. We also support multiple indexes to enable additional
        indexing strategies and access control on discovery.}
    \label{fig:twzkv}
\end{SCfigure}




\subsubsection{Extending Requirements}

Next, we added functionality to protect values with access control. We wanted to
keep handing out direct pointers to data during lookup and to
keep \nvkv a library (as opposed to a service). Meeting these goals on an
existing system would be difficult without adding significant
complexity, such as reimplementing a lot of \Twizzler's pointer framework or implementing manual,
redundant access control.

In \Twizzler, implementing access control in \nvkv involved having the index refer to data in
multiple data objects, assigning those objects different access rights, and allocating from
those objects depending on desired access rights. We were
able to implement this while preserving the original code due to the
transparent nature of \Twizzler's cross-object pointers. Now, when inserting, the application
indicates the data object into which to copy the data, as shown in Figure~\ref{fig:twzkv}.

By supporting multiple data objects, \nvkv can leverage the OS's access control,
minimizing complexity. Unrestricted data can go in $D_0$ (Figure~\ref{fig:twzkv}),
whereas restricted data can go in $D_1$. Since each object has distinct
access control, a user can set the objects' access rights, then decide
where to insert data according to policy. The indexes point to the
correct locations regardless of the access restrictions of the data objects, and \nvkv still hands
out direct pointers, but a user that is restricted from accessing data in $D_1$ will not
be able to dereference the pointer. A further extension is to support secondary indices, as shown in
Figure~\ref{fig:twzkv}, enabling alternative lookup methods and limiting data discovery
with index object access control. This extension is easy to implement on \Twizzler,
increasing our implementation's complexity only a small amount.

\subsubsection{Comparison to \unix Implementation}

To compare with existing techniques, we built a
similar KVS using only \unix features (called \unixkv). It also separates index and data, but it
must manually compute and construct pointers, requiring a significant amount of programmer time to
get right.
Supporting multiple data objects was complex in \unixkv, because we had to store and process file
paths in the index and store references to paths for pointers, increasing overhead and code
complexity by 36\%---a lot for an implementation with relatively few pointers---just to reimplement
\Twizzler's support. The extra complexity also included code to manually open, map, and
grow files, much of which \Twizzler handles internally. Development time was extended by
bugs that were not present when developing \nvkv, due to the manual pointer processing.  While \nvkv
gains transparent access control, \unixkv does not due to the lack of
on-demand object mapping and late-binding of security. Instead, \unixkv needs to know object permissions before
mapping,
a restriction that limits the ability to reuse OS access control, something that
\nvkv could leverage through late-binding on security (Section~\ref{sec:sec})\sidenote{\unixkv could trap segmentation faults to do this, but that would be
    application-specific, difficult, and would reimplement \Twizzler functionality.}. Other frameworks like PMDK
that do not integrate access control and late-binding into their models have similar
limitations.


%% TODO RUST SYNTAX
\subsection{Case Study: Red-Black Tree}
To evaluate the process of writing persistent, ``pointer-heavy'' data
structures,
we implemented a red-black tree in C using normal pointers (\ramrbt)
in 100 lines of code,
and evolved it for persistent memory in two ways: manually writing
base+offset style pointers, as current systems require (\unixrbt),
and using \Twizzler (\nvrbt).
Porting existing data structure code to persistent memory
will be common during the adoption of \NVM, and much of the complexity therein
comes from dealing with persisting virtual addresses~\cite{virendra:hotstorage17}.

In developing \unixrbt, we found 83 locations where we had to perform pointer arithmetic for
converting between object addresses and virtual addresses.  Consider an expression such as
\texttt{root->left->right = foo}. Inserting calls to translate this directly results in
\texttt{L(L(root)->left)->right = C(foo)}, where \texttt{L} converts to a virtual address and
\texttt{C} converts back, which is heavily obfuscated and took more development time than writing
\ramrbt in the first place due to debugging.

We built \nvrbt like \unixrbt, annotating pointer stores and
dereferences. However, \unixrbt used an application-specific solution for pointer
management; if other applications wanted to use the data structures created by \unixrbt, they would
have to know the implementation details of the pointer system (or share the implementation, thus
reimplementing much of \Twizzler's library).  Additionally, due to \Twizzler enabling improved
system-wide support for cross-object pointers, these transformations can be made automatic through
compiler and linker support.

Unlike \nvrbt, \unixrbt's tree is limited to a single persistent
object; a limitation that prevents the tree from growing arbitrarily, does not
allow it to directly encode references to data outside the tree object, and does
not gain it the benefits of cross-object data references that were discussed
above for \nvkv. Adding support for this to \unixrbt would require modifying the
core data structures to include paths and significantly altering the code,
increasing its length by at least a factor of 2, whereas \nvrbt gets this
functionality for free.

Another advantage of \nvrbt is reduced support code compared to \unixrbt; \unixrbt needed
code to manage and grow files and mappings, while we implemented \nvrbt as simple data structure code
with \Twizzler managing that complexity. The additional error handling code and pointer
validity checks in \unixrbt (handled automatically in \Twizzler) increased development time
and implementation complexity.


\subsection{Porting SQLite}

We ported SQLite to \Twizzler to demonstrate our support for existing software and to evaluate the
performance of a SQLite backend designed for \Twizzler. We used
our POSIX support framework, a combination of \texttt{musl} and our library
\texttt{twix}, to support much of SQLite's POSIX use.
We took a modified version of SQLite called SQLightning that replaced
SQLite's storage backend with a memory-mapped KVS called LMDB~\cite{lmdb}.
We chose this port
because LMDB is implemented with \texttt{mmap}'d files as the primary access method and hands out
direct pointers to data as one would expect from an effectively designed \NVM KVS\sidenote{These
    are not invariant pointers, however, unlike \Twizzler's.}.
Since LMDB's SQLightning port already replaces the storage backend
with calls to
LMDB, we ported SQLite to \Twizzler by taking our KVS and red-black tree code and implementing
enough of the LMDB interface for SQLite to run using \Twizzler as a backend.
Outside of the
B-tree source file few changes were needed for
SQLite to run on \Twizzler. We further ported our modified SQLite backend to PMDK to compare
directly with a commonly used \NVM programming library that supports persistent pointers.

We also ported a C++ YCSB driver~\cite{ycsbc}, which required porting the C++ standard template
library (STL). Since we had already ported a standard C library, the C++ STL was easily ported,
demonstrating the ease of porting software to \Twizzler.
We have also ported some existing \unix utilities (such as \texttt{bash} and
\texttt{busybox}), which largely require only recompiling to run on \Twizzler. Of
course, to gain \emph{all} of the benefits of \Twizzler, programs will be need to be
written with \NVM in mind (but this is true regardless of the target OS).

Our implementation of the LMDB interface
corroborated our experience from the KVS case study: much of the complexity in storage interfaces
and implementations comes from the separation between storage and memory. This has been
studied before (as we will elucidate in Section~\ref{sec:relwork}), but the advent of \NVM changes the game
significantly by allowing programmers to think directly via in-memory data structures. The result is
that interfaces like cursors in a KVS become redundant. We implemented to this interface
for LMDB, but the functions were largely wrappers around storing a pointer
to a B-tree node and traversing the tree directly without separate loads and copies. The result was
an extremely simple implementation (500 lines of code) that still met the required interface. Future software
for \NVM can use \Twizzler's programming model to more effectively write software
that eschews the need for complexity forced by the two-tier storage hierarchy.



\subsection{Case Studies Discussion}

Although these implementations were simple, they represent the applications
and data structures we expect in a data-centric system. Invariant pointers
we can directly use in our programming languages make computing over persistent
data almost transparent, allowing simple implementations that are nevertheless
easy to evolve as requirements change.

Not only does \nvkv have strong support for access control, it enables
concurrent use of databases via cross-object pointers. Applications can load indexes
for multiple databases without needing to worry about address space layout and
without writing complex pointer management code that would be required by an
implementation using \texttt{mmap}.
We were able to provide access
control without a single line of code in \nvkv dedicated to checking or enforcing
access rights. Instead, we relied on \Twizzler's built-in access control, something not possible with other
frameworks that do not support late-binding of access rights and do not consider
security as part of their programming model. \Twizzler thus removes
the need for applications to enforce and implement their own access control, which
increases the security of the system by divesting programmers from
the responsibility of getting the enforcement right.
Similar functionality for current
systems would traditionally require separation of the library and application
into a client-server model, but that additional overhead is unneeded here and
inappropriate on a persistent memory system.

Although \nvrbt and \nvkv had different densities of pointer operations, \nvrbt being
``pointer-heavy'' and \nvkv being ``pointer-light'', \Twizzler improved the complexity of both
over manual implementation and improved flexibility over existing persistent
pointer methods. Using a system-wide standardized approach to
pointer translations not only enables better compiler and hardware support, but it also improves
interoperability; because they share a common framework, \nvkv could use the red-black tree code and data with ease, and even interact with
the SQLite database even though they were written separately without that goal in mind.
%\emph{because} they share a common framework.
The position-independence afforded by this model
enables both composability and concurrency, while also simplifying programming on persistent data to
a natural expression of data structures.


\subsection{Storage Overhead}

One important consequence of replacing virtual address pointers with invariant pointers is storage
overhead. While our design choice to indirect the pointer resolution through a per-object table
means we can avoid increasing pointer size\sidenote{As we will see, this choice is meaningful for
    performance overhead.}, we must still consider the size ot that table when
considering the impact of invariant pointers. Of course, a direct comparison to virtual address
pointers is somewhat inappropriate, as virtual addresses are not invariant and thus do not have the
same semantics and power, we can use them as a baseline for comparing the increased overhead
\emph{factor} of Twizzler versus a ``fat pointer'' style persistent pointer.

Such a style of pointer is present in PMDK~\cite{pmdk-pointers}, which includes an address space of
objects with 64~bit IDs, indexed into with a 64~bit offset. Thus a pointer in PMDK is 128~bits
total, and the overhead relative to virtual addresses is exactly $2$. However, PMDK's ID space is much
smaller than Twizzler's (64~bits versus 128~bits). As we discussed in Chapter~\ref{ch:global}, the
large ID space is vital for our needs and provides useful semantics that a smaller space misses.
Adjusting PMDK's pointer model by increasing the ID size brings it to 192~bits per pointer, with a
relative overhead\sidenote{Here $F_{f128}$ means ``the overhead factor of a fat-pointer design with
    an ID space of 128~bits''.} of $F_{f128} = 3$.

In Twizzler, the overhead relative to virtual addresses is entirely dependent not on the number of
pointers, but the number of FOT entries. Each FOT entry is 256~bits in size, so the relative
overhead is:

\begin{equation*}
    \eqnmarkbox[Green]{factor}{F_T}
    = \frac{64
        N_p
        + 256
        N_f
    }{64
        N_p
    }
    = 1 + \frac{4
        \eqnmarkbox[Orange]{fot}{N_f}
    }{
        \eqnmarkbox[NavyBlue]{total1}{N_p}
    }
\end{equation*}
\annotate[yshift=-0.2em]{below}{total1}{Total \# of pointers}
\annotate[yshift=0.5em]{above}{fot}{Total \# of FOT entries}
\annotate[yshift=-0.5em]{below}{factor}{Twizzler's overhead factor}


While the above relationship is useful for determining what the overhead factor is, the ratio
between the number of pointers and the number of FOT entries is application dependent. Some
applications will have a large number of references within a small number of objects or will have a
lot of intra-object references, and thus will have a small overhead factor, while another
application may have a large number of outgoing references per object. Anecdotally, the former has
been far more common, which makes sense---objects are an projection of logical locality into an ID
space, and thus an application with a large overhead factor is, inherently, structuring its data
without significant locality.

However, we can model some real data structures to better understand how their overhead factors are
influenced by different elements of data structure organization. Figure~\ref{fig:fotoverhead} shows
the overhead factors of Twizzler and PMDK (or, more broadly, fat-pointer designs) with different
choices for object ID sizes and with different characteristics for data organization. We generated
random graphs using a stochastic process that selected edges randomly with a bias towards edges that
were between nodes that were close in an ID space. Once the graphs were generated, the nodes were
assigned to object IDs in batches. The bias was present to model organizing a graph with locality
in-mind.

The generated graphs could be either dense (many edges per node) or sparse (few edges per node), and
the objects could be either numerous and hold few objects, or there could be few objects that held
many nodes. Figure~\ref{fig:fotoverhead} shows that Twizzler's per-FOT overhead is better than the
fat-pointer style in most cases, with the exception of having few nodes per object and a spare
graph. This result correlates with the above equation. Some simple rearranging shows that to beat
the overhead factor of $F_{f128} = 3$ one needs two pointers per FOT entry. When an object has many
outgoing references to few objects, this threshold is quickly surpassed.


\begin{SCfigure}[t]
    \centering
    \includegraphics{genfig/fotoverhead}
    \caption{Storage overhead of Twizzler compared with PMDK at different object ID sizes. PMDK, or fat-pointer style references have a constant overhead per pointer. Note that Twizzler's object ID size is 128~bits, thus the closest comparison is not baseline PMDK, but instead PMDK~128. In most cases, Twizzler has a better overall storage overhead, except in the pessimistic case where many FOT entries are needed.}
    \label{fig:fotoverhead}
\end{SCfigure}




\subsection{Performance}
\label{sec:res}

Our evaluation's primary focus is on the benefits of the programming model, showing new
functionality with reduced complexity at an acceptable overhead. Nevertheless, there are many
cases where we see significant improvement (such as SQLite)
because the programming model has less overhead, and our pointer design is space
efficient and fast to translate.

We measured the performance of our KVS and red-black tree, performed
microbenchmarks, and evaluated the \Twizzler port of
SQLite against Linux (Ubuntu 19.10) instances of SQLite, SQLightning, and our port of SQLite
to PMDK\@. Tests ran on an
Intel Xeon Gold 5218 CPU running at 2.30 GHz with 192 GB of DRAM and 128 GB of Intel Optane
Persistent DIMMs.
We compiled all tests against the \texttt{musl} C library instead of
\texttt{glibc} because \Twizzler uses \texttt{musl} to support \unix programs.

All Linux tests used the NOVA filesystem~\cite{Xu:nova} (a filesystem
optimized for \NVM) on the NVDIMMs, mounted in DAX mode. This enabled direct access to the
persistent memory without a page-cache interposing on accesses.
%The use of persistent memory allows
%us to account for differences in behavior of the NVDIMMs compared to DRAM.

\subsubsection{Microbenchmarks}

Table~\ref{tbl:res} shows common \Twizzler functions' latencies, including pointer
translation (loading and storing) and mapping overhead.
The overhead shown for resolving pointers does not
include dereferencing the final result, since that is required regardless of how a pointer is
resolved. The first row shows the latency for resolving pointers to objects the first time.
\Twizzler makes a further optimization by
caching the results of translations for a given FOT entry. Each successive
time that FOT entry is used to resolve a pointer, the result of the original translation is returned
immediately, improving the latency as shown on the ``cached'' row of Table~\ref{tbl:res}. Note that
the low latency of these results is expected; the performance critical case of these functions' use
is repeated calls, and since these operations are simple, they fit within the processor cache.

\Twizzler translates intra-object pointers by first
checking if the pointer is internal and, if so, adding the object's base
address to it---the same operation required for application-specific
invariant pointers. The expanded programming model offered by \Twizzler
makes this overhead minor relative to the high costs for persistent data access on
current systems, which have high-latency for equivalent operations.

\begin{SCtable}
    \centering
    \caption{Latency of common \Twizzler operations, including pointer loading and storing, and object
        mapping.
    }
    \begin{minipage}{\linewidth}
        \centering
        \begin{tabular}{c | S[table-format=7.1]@{\,\,\( \pm \)\hspace{-5mm}} S[table-format=0.1]}
            \textbf{Pointer Resolution Action} &
            \multicolumn{2}{c}{\textbf{Average Latency (ns)}} \\
            \hline
            %First-time translation  & 26.9 & 0.1 \\
            %Object already mapped & 5.8 & 0.1      \\
            Uncached FOT translation           & 27.9 & 0.1   \\
            Cached FOT translation             & 3.2  & 0.1   \\
            Intra-object translation           & 0.4  & 0.1   \\
            Inter-object pointer store         & 17.2 & 0.6   \\
            Intra-object pointer store         & 2.3  & 0.1   \\
            Mapping object overhead            & 49.4 & 0.2
        \end{tabular}
    \end{minipage}
    \label{tbl:res}
\end{SCtable}

The pointer store operations shown in Table~\ref{tbl:res} measure the latency of the
\texttt{ptr\_store} operation that is used to construct persistent data references in \Twizzler.
While these operations are less common than pointer loads, their overhead directly affects
applications that perform many updates to data structures.
The most common pointer store operation applications perform is internal (intra-object) pointer stores, in which the
overhead is minimal. Pointer store operations for external (inter-object) references have slightly
more overhead, since they need to perform an FOT scan to allow FOT entry reuse.



We compared our pointer translation to \unix functions.
Resolving an external pointer with an ID corresponds roughly
to a call to \texttt{open("id")}, which has a latency of $1036 \pm 15$ ns.
The comparison is not exact, of course; the pointer resolution
also maps objects, and the call to \texttt{open} must handle file system
semantics. However, the direct-access nature of \NVM results in pointer translation
achieving the same goal as opening a file does today. The pointer operations in \Twizzler accomplish
much of the same functionality as the heavier-weight I/O system calls on \unix with more utility and
less overhead.

A more direct comparison is object mapping, which has
low latency compared to \texttt{mmap} ($658.7 \pm 12.7$ ns---a $13.3\times$ speedup) though the two have similar
functionality. Since mapping occurs entirely
in userspace, cache pollution is reduced.
While both \texttt{mmap} and \Twizzler's mapping require
page-faults to occur before the data is actually mapped,
this overhead is similar in \Twizzler and \unix, and so is not
shown.


%% TODO maybe cut this
It is important to keep in context the latency of these operations, many of which
replace relatively heavy \unix operations in functionality in \Twizzler's memory-access
model. Most of the equivalent \unix operations require
at least one system call, which is untenable for low-latency persistent
storage.
The mitigations for both Spectre~\cite{spectre} and
Meltdown~\cite{meltdown} further motivate reducing system calls, especially with
NVM, since they further increase system call latency.


\subsubsection{SQLite}

We ran four variants of SQLite, three on Linux and one on \Twizzler, and compared their performance: ``SQL-Native'' (unmodified SQLite),
``SQL-LMDB'' (SQLite using LMDB as the storage backend), ``SQL-PMDK'' (SQLite using
our red-black tree on PMDK),
and ``SQL-\Twizzler'' (our port of SQLite running on \Twizzler). SQL-Native was run in \texttt{mmap} mode so that both it
and SQL-LMDB used \texttt{mmap} to access data.
We ran each on the same hardware and normalized the results.


Figure~\ref{fig:ycsb} shows the three variants' throughput under standard YCSB
workloads. The performance improvement of the LMDB and \Twizzler variants over SQL-Native is
likely due to handing SQLite direct pointers to data. However, in the \Twizzler
case we get an additional benefit of operating on data structures directly while LMDB has an
abstraction cost.

\begin{SCfigure}[t]
    \centering
    \includegraphics{genfig/ycsb}
    \caption{YCSB throughput, normalized (higher is better). \Twizzler outperforms all other
        variants in all tests.}
    \label{fig:ycsb}
\end{SCfigure}

Figure~\ref{fig:qlat} shows the latency of queries on a one million row table.
This is common data processing---loading and then
examining data in a variety of ways.
%The transaction overhead is minimal, since the
%measurements are done on read-only operations.
We measured the performance
of calculating the mean and median, sorting rows, finding a specific row,
building an index, and probing the index. SQL-\Twizzler had similar performance to SQL-LMDB and
SQL-Native despite comparing its extremely simple storage backend to optimized B-tree
backends (that benefit from scan operations). As a more direct comparison,
SQL-\Twizzler significantly out-performed SQL-PMDK in most tests. PMDK's pointer operations are
more expensive than \Twizzler's, requiring up to two hash table lookups per
translation~\cite{pmdk-pointers}. Additionally, PMDK's
pointers are 128~bits, while \Twizzler does not increase pointer size. Increased
pointer size results in significantly worse cache performance, especially in a pointer-heavy data
structure like a persistent red-black tree.


%SQL-\Twizzler out-performed SQLite and SQL-LMDB in
%every test. The building-index test did not see a dramatic performance improvement, but this largely
%involved building a volatile in-memory data structure, and thus largely avoided touching persistent memory.

\begin{SCfigure}[t]
    \centering
    \includegraphics{genfig/qlat}
    \caption{Query latency, normalized (lower is better). \Twizzler maintains a similar level of
        performance with the native and LMDB variants, despite comparing \Twizzler's simplistic
        red-black tree index
        implementation with highly optimized B-trees. \Twizzler also significantly outperforms PMDK
        despite sharing a similar implementation for the index structures.}
    \label{fig:qlat}
\end{SCfigure}


\subsubsection{Key Value Store}
\label{sec:kvperf}

We compared \nvkv to \unixkv
by inserting one
million distinct key-value pairs, followed by looking up each in-order. The inserted items were 32-bit
keys and 32-bit values, chosen to reduce the overhead of data copying since we were focusing on
pointer translation overhead.
%For similar reasons, we \texttt{memset} the index to zero (to avoid
%page-fault routines clouding the overhead of pointer translation), and we set the initial hash-table
%size to avoid expansion (since expansion code is not affected by pointer translations).
Both were
compared under two modes, single-data-object and multiple-data-objects. Both KVSes translated
between virtual and persistent addresses when storing and retrieving data, but for
multiple-data-objects, we allow for storing the data in an arbitrary object.
%Finally, we compared to \texttt{clang}'s \texttt{std::unordered\_map} for a baseline, even though
%\texttt{unordered\_map} does not store data in a separate object and uses virtual addresses instead
%of persistent pointers.

Figure~\ref{fig:kvlat} shows the latency of lookup and insert, demonstrating
that not only is the memory-based index and data object
structure that can hand out direct data pointers sufficiently low latency to
take advantage of \NVM,
%(by our measurement, we are 36$\times$ and 45$\times$
%faster than Berkeley DB on insert and lookup, respectively),
but the additional overhead of cross-object
pointers is minimal.
%When using a single data object, the overhead is reduced
%because the system can optimize pointer translations to 2 bitwise operations.
Compared to \unixkv, \nvkv has minimal overhead in the single-object case, and improves lookup
performance in the multiple-object case. The minor overhead in other cases comes with improved flexibility,
simplicity, and access control support (\unixkv does not support access control).
%Compared to \unixkv, \nvkv improves performance when multiple data objects are supported,
%has significantly
%simpler code, and supports access control mechanisms (which \unixkv does not).
%When using single data objects, \unixkv avoids some of the overhead at the cost of flexiblity.
%The difference in latency on insert between the KV stores and
%\texttt{unordered\_map} can be explained by
%different choices in hashing
%algorithms,
%lack of support for persisting the index and data.%, but that the additional overhead was small.
%, and different
%optimization levels stemming from code maturity.
Finally,
multithreaded access on \nvkv and \unixkv did not improve performance;
despite the pointer translations, they ran at memory bandwidth (for \NVM).
%It is important to note that this performance is achieved with stright-forward
%code using \Twizzler's programming model, while providing the features of a
%usable KV store. Additionally, access control is provided at little to no
%additional cost in the implementation---there is no explicit code doing access
%control checks, instead all access control is handled by the OS
%during mapping, followed by being handled by the memory system.

\begin{SCfigure}[t]
    \centering
    \includegraphics{genfig/kvs}
    \caption{Latency of insert and lookup in \nvkv and \unixkv.
        An ``(m)'' indicates
        support for multiple data objects. Both \unixkv and \nvkv have similar latencies.}
    \label{fig:kvlat}
\end{SCfigure}




\subsubsection{Red-Black Tree} We measured the latency of insert and lookup of 1 million 32-bit
integers on both \unixrbt and \nvrbt. The insert and lookup latency of \nvrbt was $528 \pm 3$ ns
and $251.8 \pm 0.5$ ns, while insert and lookup latency of \unixrbt was $515 \pm 2$ ns
and $213 \pm 1$ ns.
%The lookup overhead of \nvrbt arises because it does not support cross-object trees, while the
%insert overhead of \unixrbt arises due to the management of the persistent file that is unnecessary
%in \Twizzler.
The modest overhead comes with significantly improved flexibility, as \unixrbt does not support
cross-object trees, and less support code (\unixrbt manually implements mapping and pointer
translations). Note that even though there is lookup overhead in
\nvrbt, this overhead did not predict the results of a larger program---the SQL-\Twizzler port used
this red-black tree, and saw performance benefits over block-based implementations.

%we still see a performance benefit in a larger application---the SQL-\Twizzler code used
%this red-black tree internally, and saw performance benefits during queries that were not predicted
%by this benchmark.

\begin{chconc}
    We have discussed the design and implementation of invariant references in Twizzler and demonstrated their power, flexibility, and low overhead. However, the ability to create references in
    a global address space does not a full operating system make. In the coming chapters, we will discuss the OS infrastructure needed to realize our model, along with Twizzler OS services that
    enable easier programming on the kinds of systems we are envisioning.
\end{chconc}